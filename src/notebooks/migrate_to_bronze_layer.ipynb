{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07bcda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dc43d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BUCKET = 'prod-vlc-real-estate-analytics-listings'\n",
    "SOURCE_PREFIX = ''  # Root level\n",
    "DEST_PREFIX = 'bronze/idealista/'\n",
    "REGION = 'eu-central-1'\n",
    "\n",
    "# Pattern to match listing files: sale_YYYYMMDD_HHMMSS_N.json or rent_YYYYMMDD_HHMMSS_N.json\n",
    "FILE_PATTERN = r'^(sale|rent)_\\d{8}_\\d{6}_\\d+\\.json$'\n",
    "\n",
    "# Initialize S3 client\n",
    "s3_client = boto3.client('s3', region_name=REGION)\n",
    "\n",
    "print(f\"‚úÖ Configuration loaded\")\n",
    "print(f\"   Bucket: {BUCKET}\")\n",
    "print(f\"   Source: root level\")\n",
    "print(f\"   Destination: {DEST_PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4538e8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all objects at root level using pagination\n",
    "def list_root_objects(bucket_name, pattern):\n",
    "    \"\"\"List all objects at root level matching the pattern.\"\"\"\n",
    "    objects = []\n",
    "    paginator = s3_client.get_paginator('list_objects_v2')\n",
    "    \n",
    "    # List objects at root level (no prefix)\n",
    "    for page in paginator.paginate(Bucket=bucket_name, Prefix=SOURCE_PREFIX):\n",
    "        if 'Contents' in page:\n",
    "            for obj in page['Contents']:\n",
    "                key = obj['Key']\n",
    "                # Only include files at root level (no slashes) matching pattern\n",
    "                if '/' not in key and re.match(pattern, key):\n",
    "                    objects.append(obj)\n",
    "    \n",
    "    return objects\n",
    "\n",
    "print(f\"Listing root-level listing files in {BUCKET}...\")\n",
    "root_objects = list_root_objects(BUCKET, FILE_PATTERN)\n",
    "print(f\"‚úÖ Found {len(root_objects)} listing files at root level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e38272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample of files to be migrated\n",
    "if root_objects:\n",
    "    print(\"Sample files to be migrated:\")\n",
    "    for obj in root_objects[:10]:\n",
    "        print(f\"  - {obj['Key']} ({obj['Size']} bytes, modified: {obj['LastModified']})\")\n",
    "    \n",
    "    if len(root_objects) > 10:\n",
    "        print(f\"  ... and {len(root_objects) - 10} more files\")\n",
    "    \n",
    "    # Summary by operation type\n",
    "    sale_count = sum(1 for obj in root_objects if obj['Key'].startswith('sale_'))\n",
    "    rent_count = sum(1 for obj in root_objects if obj['Key'].startswith('rent_'))\n",
    "    \n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"  - Sale listings: {sale_count} files\")\n",
    "    print(f\"  - Rent listings: {rent_count} files\")\n",
    "    print(f\"  - Total: {len(root_objects)} files\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  No listing files found at root level. Migration may have already been completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4345f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy objects from root to bronze/idealista/ folder\n",
    "def migrate_to_bronze(bucket_name, objects, dest_prefix):\n",
    "    \"\"\"Copy objects from root to bronze layer.\"\"\"\n",
    "    copied = 0\n",
    "    failed = 0\n",
    "    skipped = 0\n",
    "    \n",
    "    for i, obj in enumerate(objects, 1):\n",
    "        source_key = obj['Key']\n",
    "        dest_key = f\"{dest_prefix}{source_key}\"\n",
    "        \n",
    "        try:\n",
    "            # Check if destination already exists\n",
    "            try:\n",
    "                s3_client.head_object(Bucket=bucket_name, Key=dest_key)\n",
    "                print(f\"‚è≠Ô∏è  Skipping {source_key} (already exists at destination)\")\n",
    "                skipped += 1\n",
    "                continue\n",
    "            except ClientError as e:\n",
    "                if e.response['Error']['Code'] != '404':\n",
    "                    raise\n",
    "            \n",
    "            # Copy object\n",
    "            copy_source = {'Bucket': bucket_name, 'Key': source_key}\n",
    "            s3_client.copy_object(\n",
    "                CopySource=copy_source,\n",
    "                Bucket=bucket_name,\n",
    "                Key=dest_key\n",
    "            )\n",
    "            copied += 1\n",
    "            \n",
    "            # Progress update every 100 files\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Progress: {i}/{len(objects)} files processed ({copied} copied, {skipped} skipped, {failed} failed)\")\n",
    "                \n",
    "        except ClientError as e:\n",
    "            print(f\"‚ùå Error copying {source_key}: {e}\")\n",
    "            failed += 1\n",
    "    \n",
    "    return copied, skipped, failed\n",
    "\n",
    "if root_objects:\n",
    "    print(f\"\\nüöÄ Starting migration operation...\")\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    copied_count, skipped_count, failed_count = migrate_to_bronze(BUCKET, root_objects, DEST_PREFIX)\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    duration = (end_time - start_time).total_seconds()\n",
    "    \n",
    "    print(f\"\\n‚úÖ Migration operation completed!\")\n",
    "    print(f\"   - Successfully copied: {copied_count} files\")\n",
    "    print(f\"   - Skipped (already exist): {skipped_count} files\")\n",
    "    print(f\"   - Failed: {failed_count} files\")\n",
    "    print(f\"   - Duration: {duration:.2f} seconds\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  No files to migrate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d182bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify: List objects in bronze/idealista/ folder\n",
    "def list_bronze_objects(bucket_name, prefix):\n",
    "    \"\"\"List all objects in bronze layer.\"\"\"\n",
    "    objects = []\n",
    "    paginator = s3_client.get_paginator('list_objects_v2')\n",
    "    \n",
    "    for page in paginator.paginate(Bucket=bucket_name, Prefix=prefix):\n",
    "        if 'Contents' in page:\n",
    "            objects.extend(page['Contents'])\n",
    "    \n",
    "    return objects\n",
    "\n",
    "print(f\"\\nüîç Verifying files in {DEST_PREFIX}...\")\n",
    "bronze_objects = list_bronze_objects(BUCKET, DEST_PREFIX)\n",
    "print(f\"‚úÖ Found {bronze_objects} objects in bronze/idealista/ folder\")\n",
    "\n",
    "if root_objects:\n",
    "    if len(bronze_objects) >= len(root_objects):\n",
    "        print(\"‚úÖ Success! All files are in bronze layer.\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Warning: Expected at least {len(root_objects)} files, but found {len(bronze_objects)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c7dc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample of migrated files\n",
    "if bronze_objects:\n",
    "    print(\"\\nSample files in bronze/idealista/ folder:\")\n",
    "    sorted_bronze_objects = sorted(bronze_objects, key=lambda x: x['LastModified'], reverse=True)\n",
    "    for obj in sorted_bronze_objects[:10]:\n",
    "        print(f\"  - {obj['Key']} (modified: {obj['LastModified']})\")\n",
    "    \n",
    "    if len(bronze_objects) > 10:\n",
    "        print(f\"  ... and {len(bronze_objects) - 10} more files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb2b9e7",
   "metadata": {},
   "source": [
    "## Optional: Delete Original Root-Level Files\n",
    "\n",
    "**‚ö†Ô∏è WARNING:** This will permanently delete the original files from the root level. Only run this after verifying the migration was successful!\n",
    "\n",
    "**Before running:**\n",
    "1. Verify that all files were copied successfully (check cell above)\n",
    "2. Optionally download a backup of the bucket\n",
    "3. Uncomment the code below and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a470e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT TO DELETE ORIGINAL FILES\n",
    "# \n",
    "# def delete_root_files(bucket_name, objects):\n",
    "#     \"\"\"Delete original files from root level.\"\"\"\n",
    "#     deleted = 0\n",
    "#     failed = 0\n",
    "#     \n",
    "#     print(f\"\\n‚ö†Ô∏è  DELETING {len(objects)} files from root level...\")\n",
    "#     user_confirm = input(f\"Type 'DELETE' to confirm deletion of {len(objects)} files: \")\n",
    "#     \n",
    "#     if user_confirm != 'DELETE':\n",
    "#         print(\"‚ùå Deletion cancelled\")\n",
    "#         return deleted, failed\n",
    "#     \n",
    "#     for i, obj in enumerate(objects, 1):\n",
    "#         key = obj['Key']\n",
    "#         \n",
    "#         try:\n",
    "#             s3_client.delete_object(Bucket=bucket_name, Key=key)\n",
    "#             deleted += 1\n",
    "#             \n",
    "#             if i % 100 == 0:\n",
    "#                 print(f\"Progress: {i}/{len(objects)} files deleted\")\n",
    "#                 \n",
    "#         except ClientError as e:\n",
    "#             print(f\"‚ùå Error deleting {key}: {e}\")\n",
    "#             failed += 1\n",
    "#     \n",
    "#     return deleted, failed\n",
    "# \n",
    "# if root_objects:\n",
    "#     deleted_count, delete_failed = delete_root_files(BUCKET, root_objects)\n",
    "#     print(f\"\\n‚úÖ Deletion completed!\")\n",
    "#     print(f\"   - Successfully deleted: {deleted_count} files\")\n",
    "#     print(f\"   - Failed: {delete_failed} files\")\n",
    "\n",
    "print(\"‚è≠Ô∏è  Deletion skipped (code is commented out for safety)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978f1dd4",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The migration moves all listing files from the root level to the proper Medallion Architecture structure:\n",
    "\n",
    "```\n",
    "Before:\n",
    "‚îú‚îÄ‚îÄ sale_20230409_120044_1.json\n",
    "‚îú‚îÄ‚îÄ rent_20230409_120044_1.json\n",
    "‚îî‚îÄ‚îÄ ...\n",
    "\n",
    "After:\n",
    "‚îî‚îÄ‚îÄ bronze/\n",
    "    ‚îî‚îÄ‚îÄ idealista/\n",
    "        ‚îú‚îÄ‚îÄ sale_20230409_120044_1.json\n",
    "        ‚îú‚îÄ‚îÄ rent_20230409_120044_1.json\n",
    "        ‚îî‚îÄ‚îÄ ...\n",
    "```\n",
    "\n",
    "**Next steps:**\n",
    "1. Verify all files are in `bronze/idealista/`\n",
    "2. Test Lambda function to ensure new files go to correct location\n",
    "3. Optionally delete original root-level files (after verification)\n",
    "4. Update any downstream processes to read from bronze layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
